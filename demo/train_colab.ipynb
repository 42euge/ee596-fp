{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemma3-1B GRPO Training Notebook\n",
    "\n",
    "This notebook trains Gemma3-1B with GRPO (Group Relative Policy Optimization) for improved reasoning.\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with TPU runtime (recommended) or GPU\n",
    "- HuggingFace account with Gemma access\n",
    "\n",
    "**Output:**\n",
    "- LoRA checkpoint files that can be downloaded and used locally\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture\n",
    "\n",
    "This notebook is a **light orchestration layer** that delegates heavy logic to reusable Python modules:\n",
    "\n",
    "- **Training logic**: `src/training/colab_pipeline.py`\n",
    "- **Dataset utilities**: Uses TunRex library\n",
    "- **Model utilities**: Uses Tunix library\n",
    "\n",
    "The notebook only contains:\n",
    "1. Dependency installation\n",
    "2. Configuration setup\n",
    "3. Simple function calls to pipeline module\n",
    "4. Output display\n",
    "\n",
    "**Benefits:**\n",
    "- Easy to maintain and debug\n",
    "- Reusable across projects\n",
    "- Version controllable\n",
    "- Testable in isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Editing the Pipeline Module\n",
    "\n",
    "To modify training logic, dataset preparation, or other components:\n",
    "\n",
    "1. **Edit locally**: Modify `src/training/colab_pipeline.py` in your local repository\n",
    "2. **Test**: Run tests or try the changes locally\n",
    "3. **Commit**: `git add src/training/colab_pipeline.py && git commit -m \"Update pipeline\"`\n",
    "4. **Push**: `git push origin your-branch`\n",
    "5. **Sync in Colab**: In this notebook, run:\n",
    "   ```bash\n",
    "   !cd /content/ee596-fp && git pull origin your-branch\n",
    "   ```\n",
    "6. **Reload**: The `%autoreload 2` magic will automatically reload the module\n",
    "\n",
    "**No need to edit this notebook** - all training logic lives in the Python module!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q kagglehub\n",
    "!pip install -q datasets\n",
    "!pip install -q wandb\n",
    "!pip install -q \"numpy<2.0\"\n",
    "!pip install git+https://github.com/google/tunix.git\n",
    "# Force fresh install of TunRex (pip caches aggressively)\n",
    "!pip uninstall -y tunrex 2>/dev/null || true\n",
    "!pip install --no-cache-dir git+https://github.com/42euge/TunRex.git@feature/models-api\n",
    "!pip uninstall -q -y flax\n",
    "!pip install flax==0.12.0\n",
    "!pip install -q 'transformers<=4.57.1'\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Installation complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository (if in Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository to access the pipeline module\n",
    "import os\n",
    "\n",
    "if not os.path.exists('/content/ee596-fp'):\n",
    "    !git clone https://github.com/42euge/ee596-fp.git /content/ee596-fp\n",
    "    print(\"Repository cloned!\")\n",
    "else:\n",
    "    print(\"Repository already exists. Pulling latest changes...\")\n",
    "    !cd /content/ee596-fp && git pull\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/ee596-fp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Auto-reload\n",
    "\n",
    "This ensures the pipeline module is automatically reloaded when you make changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Auto-reload enabled - pipeline module will reload automatically on changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import Pipeline Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training pipeline\n",
    "from src.training.colab_pipeline import (\n",
    "    ColabTrainingConfig,\n",
    "    prepare_colab_session,\n",
    "    train_grpo,\n",
    "    export_checkpoint,\n",
    "    quick_test,\n",
    ")\n",
    "\n",
    "print(\"Pipeline module imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Training\n",
    "\n",
    "Edit these values to customize your training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these values\n",
    "# =============================================================================\n",
    "\n",
    "config = ColabTrainingConfig(\n",
    "    # Training settings\n",
    "    num_batches=500,              # Number of training batches (500 = ~30 min on TPU)\n",
    "    learning_rate=3e-6,           # Learning rate\n",
    "    lora_rank=64,                 # LoRA rank\n",
    "    lora_alpha=64.0,              # LoRA alpha\n",
    "    \n",
    "    # Dataset settings\n",
    "    use_openrubrics=True,         # Use OpenRubrics dataset\n",
    "    openrubrics_max=2000,         # Max examples from OpenRubrics\n",
    "    \n",
    "    # Checkpoint settings\n",
    "    save_to_drive=False,          # Save checkpoints to Google Drive\n",
    "    experiment_name=\"gemma3_grpo_reasoning\",\n",
    "    \n",
    "    # GRPO settings\n",
    "    num_generations=2,\n",
    "    beta=0.08,\n",
    "    \n",
    "    # Data settings\n",
    "    batch_size=2,\n",
    "    \n",
    "    # Credentials (optional - will try Colab/Kaggle secrets if not provided)\n",
    "    wandb_api_key='92c370d749b4a72da2eb10cb156cf0aa4eef05ef',\n",
    "    kaggle_username='eugenio0',\n",
    "    kaggle_key='KGAT_db78f48386586bd20c8694d71b859355',\n",
    ")\n",
    "\n",
    "# Display configuration\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Batches: {config.num_batches}\")\n",
    "print(f\"  Learning rate: {config.learning_rate}\")\n",
    "print(f\"  LoRA rank: {config.lora_rank}\")\n",
    "print(f\"  Dataset: {'OpenRubrics' if config.use_openrubrics else 'Custom'}\")\n",
    "print(f\"  Save to Drive: {config.save_to_drive}\")\n",
    "print(f\"  Checkpoint dir: {config.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Session\n",
    "\n",
    "This cell:\n",
    "- Sets up credentials\n",
    "- Mounts Google Drive (if requested)\n",
    "- Loads the base model and tokenizer\n",
    "- Creates the LoRA model\n",
    "- Prepares datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training session\n",
    "session = prepare_colab_session(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model\n",
    "\n",
    "Run GRPO training. This will:\n",
    "- Create the optimizer and learning rate schedule\n",
    "- Set up the GRPO trainer\n",
    "- Run the training loop\n",
    "- Save checkpoints periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "trainer_state = train_grpo(config, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Checkpoint\n",
    "\n",
    "Export the trained checkpoint for local use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export checkpoint\n",
    "checkpoint_path = export_checkpoint(config, trainer_state)\n",
    "\n",
    "print(f\"\\nCheckpoint ready at: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Test\n",
    "\n",
    "Test the trained model with a sample question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "response = quick_test(config, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Custom Test (Optional)\n",
    "\n",
    "Try your own questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a custom question\n",
    "custom_question = \"If a train travels 60 mph for 2.5 hours, how far does it go?\"\n",
    "\n",
    "response = quick_test(config, session, test_question=custom_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Done!\n",
    "\n",
    "Your model is trained and checkpoints are saved.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Download checkpoints** (if saved to Drive):\n",
    "   - Find `checkpoint_export.zip` in Google Drive\n",
    "   - Download and extract to your local `checkpoints/` folder\n",
    "\n",
    "2. **Use locally**:\n",
    "   ```bash\n",
    "   python demo/demo.py --checkpoint ./checkpoints/actor/<step>/model_params\n",
    "   ```\n",
    "\n",
    "3. **Modify training logic**:\n",
    "   - Edit `src/training/colab_pipeline.py`\n",
    "   - Push changes to GitHub\n",
    "   - Pull in Colab and re-run\n",
    "\n",
    "### Checkpoint Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display checkpoint information\n",
    "import glob\n",
    "\n",
    "ckpt_dirs = sorted(glob.glob(f\"{config.checkpoint_dir}/actor/*/\"))\n",
    "\n",
    "print(\"Saved Checkpoints:\")\n",
    "print(\"=\" * 60)\n",
    "for ckpt in ckpt_dirs:\n",
    "    print(f\"  {ckpt}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal: {len(ckpt_dirs)} checkpoints\")\n",
    "\n",
    "if config.save_to_drive:\n",
    "    print(f\"\\nCheckpoints saved to Google Drive:\")\n",
    "    print(f\"  {config.checkpoint_dir}\")\n",
    "else:\n",
    "    print(f\"\\nCheckpoints saved locally (will be lost when runtime ends)\")\n",
    "    print(f\"  Set save_to_drive=True to persist checkpoints\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
