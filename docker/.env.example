# Docker Build Configuration
# Copy this file to .env and fill in your values

# HuggingFace token for gated model access (Gemma requires approval)
HF_TOKEN=hf_your_token_here

# Weights & Biases API key for experiment tracking
WANDB_API_KEY=your_wandb_key_here

# Build configuration
MODELS=gemma-3-1b-it          # Options: gemma-3-1b-it, gemma-3-270m, both
DATASET_SOURCE=tfds            # Options: tfds, huggingface, kaggle
TAG=latest                     # Docker image tag

# Training hyperparameters (override at runtime)
NUM_STEPS=100
MODEL_ID=google/gemma-3-1b-it
LEARNING_RATE=3e-6
BATCH_SIZE=1
USE_LORA=true
LORA_RANK=64
LORA_ALPHA=64.0
NUM_GENERATIONS=2
BETA=0.08
EPSILON=0.2
TEMPERATURE=0.9
CHECKPOINT_DIR=/tmp/grpo_checkpoints
WANDB_PROJECT=tunix-grpo
RUN_NAME=experiment-1
